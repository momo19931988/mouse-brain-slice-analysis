# ðŸ§  AutoSliceQuant 
**Automated Quantification of Fluorescence Signals in Mouse Brain Slices**

This repository provides a standardized image analysis pipeline for the quantification of fluorescence signals in mouse brain slices.
The workflow integrates Python for preprocessing, image alignment, and data extraction with R for statistical analysis and visualization.

The current version is optimized for OME-TIFF images generated by the Olympus slide scanner, but since each step is modularized, the pipeline can be easily adapted to most mouse brain slice imaging datasets with minor modifications.

ðŸŽ¯ Project Motivation
Performing batch-level quantification of brain slice fluorescence imaging is often challenging due to:

- **Variability in slice positioning**
- **Orientation misalignment**
- **Inconsistent brain region identification**

This project addresses these challenges by:
**Converting brain slice images into fluorescence coordinate maps**
**Supporting region-of-interest (ROI) extraction through napari for brain regionâ€“specific analysis**
**Enabling high-precision, large-scale quantification across multiple slices**

 
<img width="536" height="205" alt="image" src="https://github.com/user-attachments/assets/f55a2a0a-f6b5-4844-ab7e-9b7b78dd43c0" />

---

## ðŸ“‚ Project Structure

```
project/
â”œâ”€â”€ README.md         # Project introduction (this file)
â”œâ”€â”€ requirements.txt  # Python dependencies
â”œâ”€â”€ cellprofiler      # fluorescence signals coordinate extraction
â”œâ”€â”€ analysis.Rmd      # R script for statistical analysis
â”œâ”€â”€ pipeline/         # Python scripts for image analysis
â”‚   â”œâ”€â”€ step1.py      # Adjust brain slice orientation
â”‚   â”œâ”€â”€ step2.py      # Standardize image size
â”‚   â”œâ”€â”€ step3.py      # Extract fluorescence channels (NMF)
â”‚   â”œâ”€â”€ step4.py      # Align images (SimpleITK)
â”‚   â”œâ”€â”€ step5.py      # Downsample images
â”‚   â”œâ”€â”€ step6.py      # Intensity normalization
â”‚   â””â”€â”€ step7.py      # Extract brain region coordinates
â”œâ”€â”€ gui/              # Graphical User Interface (Tkinter)
â”‚   â””â”€â”€ GUI.py
â””â”€â”€ docs/             # Documentation and example images
    â”œâ”€â”€ workflow.png  # Example workflow diagram
    â””â”€â”€ example.png   # Input/output illustration
```

---

## ðŸ”¹ Features
- **Channel separation** for fluorescence images (e.g., DAPI)  
- **PCA-based slice alignment** to correct orientation differences  
- **Background subtraction & intensity normalization** across groups  
- **Coordinate extraction** of fluorescence signals from individual cells or regions  
- **Standardized brain region mapping** for cross-slice comparison  
- **Batch processing** with GUI support  
- **Statistical analysis (R)** including GO/KEGG enrichment, barplots, and dotplots  
- **Export** of results as CSV tables and annotated figures  

---

## ðŸš€ Installation

### Python
Clone the repository and install dependencies:
```bash
git clone https://github.com/momo19931988/mouse-brain-slice-analysis.git

pip install -r requirements.txt
```

Typical dependencies include:
```txt
numpy
scipy
pandas
opencv-python
matplotlib
scikit-learn
tifffile
cellprofiler-core
tkinter      
```

---

### Cellprofiler
Required Cellprofiler:
```
https://cellprofiler.org/releases
```

---


### R
Required R packages:
```R
install.packages(c("ggplot2", "dplyr","readr","sp","tidyr"))

```

---

## ðŸ›  Usage

### Run the GUI
```bash
python gui/GUI.py
```
This launches a Tkinter-based interface for **one-click batch processing**, including preprocessing, normalization, and export.

<img width="832" height="680" alt="image" src="https://github.com/user-attachments/assets/282a145f-7a84-4ea9-a212-5c23f621d048" />



### Workflow for automated alignment of mouse brain slice images.
<img width="527" height="794" alt="image" src="https://github.com/user-attachments/assets/5c192985-107b-427c-87e9-6b534691923b" />

- This process consists of three main steps: 1. Contour extraction â€“ the outline of the brain slice is identified from the raw image. 2. Point cloud generation and principal component extraction â€“ the contour is transformed into a set of points, and principal component analysis (PCA) is applied to determine the primary (PC1) and secondary (PC2) axes of variation. 3.Rotation correction â€“ brain slices are rotated according to the PC1 axis to align the long axis horizontally, ensuring consistent orientation across samples.

- ðŸ”¹ Step 4: Align images (SimpleITK)
In this step, fluorescence channels are spatially aligned using the DAPI channel as a reference.

  A template DAPI image is selected as the reference.
  Each image stack (e.g., DAPI, TH, Iba1) is read.
  SimpleITKâ€™s image registration is applied, using mutual information as the similarity metric and an Euler transform to correct for translation and rotation.
  After alignment, all channels are resampled into the same coordinate space as the template.

âœ… Output: aligned fluorescence channel images (e.g., *_channel1_aligned.tif, *_channel2_aligned.tif, â€¦).

### Extract brain region coordinates(step7)
<img width="882" height="587" alt="image" src="https://github.com/user-attachments/assets/86009998-1726-4d29-a167-21dd8aa37355" />

- First, change the path in advance: image_path = Path("C:/*******/image9_channel1_aligned.tif"). Then, draw the region you want to analyze and select save selected layer to obtain the coordinates of the brain area of interest.
### Downstream Cellprofiler analysis

- After the preceding image processing steps, the fluorescence images can be used by analysis software such as CellProfiler to extract signal coordinates. (In later versions, this functionality will be considered for integration into the Python platform.
```
source("ihc.cpproj")
```
### Downstream R analysis
```R
source("analysis.Rmd")
```
- In the provided R script, you can link the extracted brain region coordinates with the fluorescence signal coordinates. The figure below shows the integrated DAPI coordinates (in red) from multiple brain slices, with the selected brain region for analysis highlighted in green.
<img width="700" height="432" alt="èƒŒæ™¯1" src="https://github.com/user-attachments/assets/04d2f2d4-3e2e-4eff-b6ab-b35b7f0d936b" />


Results include:
- CSV tables with normalized intensity values (saved in `output/`)  
- Group comparisons across brain regions  
- Figures (PNG/PDF) for statistical plots  

---

## ðŸ“Š Example Workflow 
1. **Input:** Raw fluorescence images (`.tif`) from mouse brain slices  
2. **Preprocessing:** Channel separation, background correction  
3. **Alignment:** PCA-based slice rotation correction  
4. **Quantification:** Intensity normalization & coordinate extraction (Cellprofiler)
5. **Analysis:** Group-level comparison (R)  
6. **Output:** CSV files + annotated plots (example in `docs/example.png`)  

---

## ðŸ“– Documentation
See the [`docs/`](./docs) folder for:
- Workflow diagrams (`workflow.png`)  
- Example input/output images  
- Additional technical notes 

---

## ðŸ“„ License
This project is released under the [MIT License](https://opensource.org/licenses/MIT).  

---

## âœ¨ Citation
Until the formal publication of the manuscript, please cite this repository as:  

This section will be updated once the related article is published.  

In addition, since AutoSliceQuant makes use of **napari** for ROI extraction and visualization,  
please also cite napari as recommended by its authors:

napari contributors (2019). napari: a multi-dimensional image viewer for python.  
Zenodo. https://doi.org/10.5281/zenodo.3555620

---
